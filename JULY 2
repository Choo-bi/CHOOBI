## Machine Learning 시스템 
=> 입력값을 결합해 이전에 없는 데이터를 예측하는 방법을 학습하는 시스템


라벨 : 예측하는 실제 항목 (Y)
특성 : 데이터를 설명하는 입력 변수 (X) {X1,X2,...,Xn}같은 형태

예는 데이터(x)의 특정 인스턴스

** 라벨이 있는 예 {x, y}
- 모델을 학습시키는데 사용

** 라벨이 없는 예 {x, ?}
- 새 데이터를 예측하는데 사용

모델은 예를 예측된 라벨(y`)에 매핑한다.
- 학습되는 내부 매개변수에 의해 정의


## 선형 회귀

** 손실함수
=> 회귀에 사용할떄 편리

주어진 예의 L손실은 제곱오차라고한다.
= 예측과 라벨간의 차이 제곱
= (관찰 - 예측)^2

평균 제곱 오차(MSE)는 예시당 평균 제곱 손실입니다. 
MSE를 계산하려면 개별 예의 모든 제곱 손실을 합한 다음 예의 수로 나눕니다.

MSE = 1/N 시그마(y - 예측값(y`))^2

** 선형 관계
y`= w1x1 + b (예측값 선형 함수)

y′는 예측된 라벨(얻고자 하는 출력)
? b는 편향(y절편) 일부 머신러닝 자료에서는 (w_0\)이라고 한다.
? w1은 특성 1의 가중치. 가중치는 '기울기'와 같은 개념
? x1은 특성(알려진 입력)

x1새로운 분당 우는 횟수 에서 온도y′를 추론(예측)하려면 
x1 값을 이 모델에 대입하기만 하면 됩니다.

아래 첨자(예: w1, x1)는 여러 특성에 의존하는 좀 더 정교한 모델을 예시로 한다. 
예를 들어 세 가지 특성에 의존하는 모델은 다음과 같은 방정식을 사용함.
y` = w1x1 + w2x2 + w3x3 + b 

## 손실 줄이는 방법
1.가중치와 편향에 대한 도함수 (y-y`)^2는 주어진 예제의 손실변화정도를 보여줌.
--> 계산하기 간편하며 볼록모양
2. 손실을 최소화 하는 방향으로 작은 보폭을 반복하여 업데이트한다.
이를 가리켜 '기울기 보폭'(실제론 음의 기울기 보폭)이라 하고,
이 최적화 전략을 '경사하강법'이라 한다.

손실값을 극솟값에 가깝게하는데 손실함수에 대입하여 구한 기울기값을 통해 극솟값에 도달하게한다.
(기울기를 0에 가깝게)

전자더빙음 너무나 거슬리는데 유다시티보단 낫네 ㅋ
